{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be649d9-f72c-43b8-b9e0-6785862286a4",
   "metadata": {},
   "source": [
    "## What do my notes look like?\n",
    "\n",
    "Because your lab workbench and your notes have been using wikilinks to tie together thoughts and observations (right? You've been doing that? Yes?) there will be emergent structures in your thinking that you might not have spotted yet.\n",
    "\n",
    "That is to say, we network our thinking, stitching together thoughts and ideas. This notebook uses what you've explored this week (via python) to visualize and quickly analyze the structure of your workbench. The first cell defines all of the functions we'll use; the second cell executes those functions against the [[wikilink-index.json]] file that stores the information about how your notes interlink. (You can find that json file in the top-level of your workbench folder. If it's not there, go to View -> Command Pallette -> PKM: Build/Rebuild Wikilink Index to create it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86230c3e-a883-49c9-80f5-6fd7d22d0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "def load_wikilink_data(filepath):\n",
    "    \"\"\"Load the wikilink JSON file.\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def clean_filename(filename):\n",
    "    \"\"\"Remove file extensions and clean up filenames for display.\"\"\"\n",
    "    # Remove common file extensions\n",
    "    filename = re.sub(r'\\.(md|ipynb|json|csv|py)$', '', filename)\n",
    "    # Remove directory paths\n",
    "    filename = filename.split('/')[-1]\n",
    "    return filename\n",
    "\n",
    "def filter_checkpoints_and_clean(data):\n",
    "    \"\"\"Filter out checkpoint files and clean the data.\"\"\"\n",
    "    links = data.get('links', {})\n",
    "    filtered_links = {}\n",
    "    \n",
    "    for source, targets in links.items():\n",
    "        # Skip checkpoint files\n",
    "        if 'checkpoint' in source.lower():\n",
    "            continue\n",
    "            \n",
    "        clean_source = clean_filename(source)\n",
    "        clean_targets = []\n",
    "        \n",
    "        # Handle both list and dict formats for targets\n",
    "        target_list = targets if isinstance(targets, list) else list(targets.keys())\n",
    "        \n",
    "        for target in target_list:\n",
    "            # Skip checkpoint files and complex references\n",
    "            if ('checkpoint' not in target.lower() and \n",
    "                not target.startswith('`') and  # Skip code snippets\n",
    "                not target.startswith('http') and  # Skip URLs\n",
    "                '#' not in target):  # Skip specific cell/section references for cleaner view\n",
    "                clean_targets.append(clean_filename(target))\n",
    "        \n",
    "        if clean_targets:  # Only add if there are valid targets\n",
    "            filtered_links[clean_source] = clean_targets\n",
    "    \n",
    "    return filtered_links\n",
    "\n",
    "def create_graph(filtered_links):\n",
    "    \"\"\"Create a NetworkX graph from the filtered wikilink data.\"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for source, targets in filtered_links.items():\n",
    "        for target in targets:\n",
    "            if source != target:  # Avoid self-loops\n",
    "                G.add_edge(source, target)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def show_graph_info(G):\n",
    "    \"\"\"Print basic information about the graph.\"\"\"\n",
    "    print(f\"ðŸ“Š Graph Statistics:\")\n",
    "    print(f\"   Nodes (notes): {len(G.nodes())}\")\n",
    "    print(f\"   Edges (connections): {len(G.edges())}\")\n",
    "    \n",
    "    if len(G.nodes()) > 0:\n",
    "        avg_connections = sum(dict(G.degree()).values()) / len(G.nodes())\n",
    "        print(f\"   Average connections per note: {avg_connections:.1f}\")\n",
    "        \n",
    "        # Find most connected notes\n",
    "        degrees = dict(G.degree())\n",
    "        most_connected = sorted(degrees.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print(f\"\\nðŸ”— Most connected notes:\")\n",
    "        for note, connections in most_connected:\n",
    "            print(f\"   {note}: {connections} connections\")\n",
    "\n",
    "def plot_graph(G, filtered_links):\n",
    "    \"\"\"Create a clean visualization of the graph.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    if len(G.nodes()) == 0:\n",
    "        ax.text(0.5, 0.5, 'No valid links found\\n(Try creating some [[wikilinks]] in your notes!)', \n",
    "                ha='center', va='center', fontsize=16)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "    else:\n",
    "        # Use spring layout for better node distribution\n",
    "        pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "        \n",
    "        # Calculate node sizes based on degree (number of connections)\n",
    "        degrees = dict(G.degree())\n",
    "        node_sizes = [max(300, degrees[node] * 100) for node in G.nodes()]\n",
    "        \n",
    "        # Create color map based on degree\n",
    "        node_colors = [degrees[node] for node in G.nodes()]\n",
    "        \n",
    "        # Draw the graph\n",
    "        nodes = nx.draw_networkx_nodes(G, pos, \n",
    "                                      node_size=node_sizes,\n",
    "                                      node_color=node_colors,\n",
    "                                      cmap=plt.cm.viridis,\n",
    "                                      alpha=0.8,\n",
    "                                      ax=ax)\n",
    "        \n",
    "        nx.draw_networkx_edges(G, pos, \n",
    "                              alpha=0.5, \n",
    "                              edge_color='gray',\n",
    "                              width=1,\n",
    "                              ax=ax)\n",
    "        \n",
    "        # Add labels with better positioning\n",
    "        labels = {node: node for node in G.nodes()}\n",
    "        nx.draw_networkx_labels(G, pos, labels, \n",
    "                               font_size=8, \n",
    "                               font_weight='bold',\n",
    "                               font_color='black',\n",
    "                               ax=ax)\n",
    "        \n",
    "        # Add a color bar for node colors\n",
    "        if len(set(node_colors)) > 1:  # Only add colorbar if there's variation\n",
    "            plt.colorbar(nodes, ax=ax, label='Number of connections', shrink=0.8)\n",
    "    \n",
    "    ax.set_title('Your Personal Knowledge Network ðŸ§ \\n(Node size = number of connections)', \n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_knowledge_network(filtered_links):\n",
    "    \"\"\"Provide insights about the knowledge network structure.\"\"\"\n",
    "    print(f\"\\nðŸŽ¯ Knowledge Network Insights:\")\n",
    "    \n",
    "    # Count different types of connections\n",
    "    total_connections = sum(len(targets) for targets in filtered_links.values())\n",
    "    print(f\"   Total wikilink connections: {total_connections}\")\n",
    "    \n",
    "    # Find notes that are referenced but don't exist yet (red links)\n",
    "    all_sources = set(filtered_links.keys())\n",
    "    all_targets = set()\n",
    "    for targets in filtered_links.values():\n",
    "        all_targets.update(targets)\n",
    "    \n",
    "    missing_notes = all_targets - all_sources\n",
    "    if missing_notes:\n",
    "        print(f\"   ðŸ“ Notes referenced but not created yet: {len(missing_notes)}\")\n",
    "        print(f\"      Examples: {', '.join(list(missing_notes)[:10])}\")\n",
    "    \n",
    "    # Suggest connections\n",
    "    if len(filtered_links) > 0:\n",
    "        print(f\"\\nðŸ’¡ Tips for building your knowledge network:\")\n",
    "        print(f\"   â€¢ Create the missing notes to strengthen connections\")\n",
    "        print(f\"   â€¢ Look for opportunities to link related concepts\")\n",
    "        print(f\"   â€¢ Most connected notes might be good 'hub' pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4cd4d0-1845-4928-8d23-70722fb732d3",
   "metadata": {},
   "source": [
    "## Now let's do it!\n",
    "\n",
    "Run the next cell. Which notes are most important? Why? What does that tell you about your own thinking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d81ea-6a94-474a-8662-56904d1bf0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the data\n",
    "data = load_wikilink_data('../wikilink-index.json')\n",
    "filtered_links = filter_checkpoints_and_clean(data)\n",
    "\n",
    "# Create the graph\n",
    "graph = create_graph(filtered_links)\n",
    "\n",
    "# Show statistics and insights\n",
    "show_graph_info(graph)\n",
    "analyze_knowledge_network(filtered_links)\n",
    "\n",
    "# Create the visualization\n",
    "plot_graph(graph, filtered_links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
