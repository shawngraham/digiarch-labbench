{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ecaed7-5516-43c4-ab41-d187fac6deb3",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "We need to get the python package that works with Python, 'networkx', and then tell Python we're going to use it and a few other pieces of useful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caaee95-4c34-4404-83bb-cd8e03a7411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef04239-849f-41ba-86ca-172dfcf34d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import networkx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a6d55-fe1e-4d78-b1e4-92cb5cd87280",
   "metadata": {},
   "source": [
    "### Grab the Data!\n",
    "\n",
    "The dataset page describing the metadata is at https://purl.stanford.edu/mn425tz9757. That page also shows us two files, one with the orbis edges: https://stacks.stanford.edu/file/mn425tz9757/orbis_edges_0514.csv and one with the orbis nodes: https://stacks.stanford.edu/file/mn425tz9757/orbis_nodes_0514.csv.\n",
    "\n",
    "We'll download that data and turn both into a 'dataframe' that Python can manipulate. Once you've got the data though double click on the csv files and have a look at what you've obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca6b87-e297-48f9-a2b0-161ecac36e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make a nice function to retrieve data we want\n",
    "def save_csv(url, filename):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200: #which means, we ping'd the url and found there was something there\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923cdf9-deca-4964-b590-7a7411967b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_edges = 'https://stacks.stanford.edu/file/mn425tz9757/orbis_edges_0514.csv'\n",
    "url_nodes = 'https://stacks.stanford.edu/file/mn425tz9757/orbis_nodes_0514.csv'\n",
    "\n",
    "filename1 = 'edges.csv'\n",
    "filename2 = 'nodes.csv'\n",
    "\n",
    "save_csv(url_edges, filename1)\n",
    "save_csv(url_nodes, filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f97d2-b273-4c0a-88d3-61e138bac35a",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "\n",
    "First we turn the csv files into dataframes that Python can manipulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109491f-4664-487f-bd98-b85dedfe2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = pd.read_csv('edges.csv')\n",
    "nodes_df = pd.read_csv('nodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a3486-8780-410e-9b39-bb1405367b17",
   "metadata": {},
   "source": [
    "The next block of code builds up a network one step at a time. We create a variable called `G` that we're going to tell python, \n",
    "\n",
    "1. 'hey, use the networkx package's function 'from pandas edgelist' to load up edges_df, and create a network where the source node for a relationship is in the 'source' column, the target for the relationship is in the 'target' column, and the stregth of the relationship will be however many days it takes to get from source -> target'.\n",
    "2. 'hey, these nodes are all specified by a numbers, so go look at the nodes table and create a dictionary where we can look up any id number and find the actual label/name of the settlement'.\n",
    "3. 'hey, use the set_node_attributes function from networkx with that dictionary id_to_label so that in our graph, we now have the right label for each node.\n",
    "\n",
    "The next bit uses functions from matplot (via its knickname, plt) to create a new figure. We tell it to use an algorithm called 'spring layout' to figure out the position of each node for visualization. With spring layout, you imagine each edge in the graph as a spring whose strength is set by its attributes. This pushes/pulls the nodes so that you can see something of the structure. There are many different layouts possible, but it's important to remember: UNLESS YOU'RE ACTUALLY USING GEOGRAPHIC COORDINATES for positioning, the x and y layout itself carries no meaning - something higher up the page isn't 'more important', for instance.\n",
    "\n",
    "Then, finally, we use networkx's 'draw' functions to build our visualization of our graph, G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7869dc-07bf-4071-a57f-4b80b0911f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph from edges\n",
    "G = nx.from_pandas_edgelist(edges_df, source='source', target='target', edge_attr='days')\n",
    "\n",
    "# Create a mapping from node id to label\n",
    "id_to_label = dict(zip(nodes_df['id'], nodes_df['label']))\n",
    "\n",
    "# Add node attributes to the graph\n",
    "nx.set_node_attributes(G, id_to_label, 'label')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Choose a layout (you can experiment with different ones)\n",
    "pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "\n",
    "# Draw the network\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5, edge_color='gray')\n",
    "nx.draw_networkx_nodes(G, pos, node_color='lightblue', \n",
    "                       node_size=50, alpha=0.8)\n",
    "\n",
    "# Draw labels using the label attribute\n",
    "labels = nx.get_node_attributes(G, 'label')\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=5)\n",
    "\n",
    "plt.title(\"Network Graph\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f596076b-d4e7-4145-919a-3da340c95266",
   "metadata": {},
   "source": [
    "We *do* have the X and Y positioning for the nodes, so we *could* lay this network out by geographic positioning. However, if you check the nodes.csv, you'll see that there are some errors and missing data in the positioning values. We would have to do a bunch of data cleaning to fix that, either finding the correct x and y adjusted for this dataset, or by cleaning/filtering that data out. And THAT would have an impact on what comes next. Having some holes in our x,y data is only a problem if we are trying to lay the graph out using the x and y positioning; we're not doing spatial analysis here. Network analysis is powerful precisely because it explores _relative_ positioning and for this data - _this_ city connects to _that_ one, in x days - is all present. So let's see what we can see!\n",
    "\n",
    "(Incidentally, if you spot a long tail of connected cities/settlements in the visualization, you've just spotted Egypt! And if you notice that the whole thing is kinda arranged around two areas of lesser 'holes', you've just spotted the eastern and western halves of the Mediterranean!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a59392-b367-4b61-8033-913b653e9c5e",
   "metadata": {},
   "source": [
    "## Measuring a Network \n",
    "By looking at how different nodes connect or not, we can begin to examine questions like, how are individual cities or settlements in positions to control information flow? This might hold implications for economic or social development. We might ask, are there any subgroups implied by these connections? And so on. It's important to always try to imagine: what does this metric mean in the _context_ of my data?\n",
    "\n",
    "### Degree\n",
    "The simplest indication of importance in a network is a metric called ‘degree’ or the number of connections a node has. What might it mean that a city has the most connections to other cities?\n",
    "\n",
    "We can calculate degree like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300e3a2-5dba-4d25-86bc-85295504f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkx.degree(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb69e5e9-7f49-4614-aa5d-0fedb4a43383",
   "metadata": {},
   "source": [
    "...but that's just a list of id's and degree measurements and unless you've got a really good memory, not all that useful. So let's see if we can make a _new_ dataframe that will have three columns: node, degree, and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83064c4-9119-4adf-a7a1-85e0c7f40565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get degrees and labels from the graph\n",
    "degrees = dict(G.degree()) #we create a dictionary where the calculated 'degree' statistic is written down for each node \n",
    "labels = nx.get_node_attributes(G, 'label') # we also get the labels for each node\n",
    "\n",
    "# then we use pandas (pd) function 'DataFrame' to get the node, dgree, and label for each node.\n",
    "degree_df = pd.DataFrame([\n",
    "    {'node': node, 'degree': degrees[node], 'label': labels.get(node, node)}\n",
    "    for node in G.nodes()\n",
    "])\n",
    "\n",
    "# and let's sort the dataframe so that we can see which settlements have the highest number of connections:\n",
    "degree_df = degree_df.sort_values(by='degree', ascending=False)\n",
    "\n",
    "# and then let's take a look!\n",
    "degree_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884c2cb-dccb-4d6d-94ef-75c2e84b566b",
   "metadata": {},
   "source": [
    "If you're a student of ancient history, the top 5 cities/settlements are going to jump right out at you. What do you think this implies about the cultural, economic, or historical importance of those cities? What era does this data represent, anyway?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ba65f-fe2a-4479-b587-72f9290710df",
   "metadata": {},
   "source": [
    "#### Your Observations\n",
    "\n",
    "Make some observations here. Also, if you'd like, it is possible to make a very nice bar histogram showing that same information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cbf2c5-84d8-4756-b7ef-cf2c65de7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_to_inspect = 10\n",
    "degree_df[:num_nodes_to_inspect].plot(x='label', y='degree', kind='barh').invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5593b-e147-466b-91ef-670f45ff9d6f",
   "metadata": {},
   "source": [
    "### Betweeness Centrality\n",
    "\n",
    "What does it mean to be 'central' in a graph or network? There are lots of ways of measuring this. Degree can be seen as the simplest measure of being 'central' or important in the overall structure. Another measure is 'closeness', which looks at every node and works out the average length of the shortest path from it to every other node. Thus a node or settlement that has a low average length to all other nodes is very central! Another measurement is 'betweewness centrality' and I tend to use this metric a lot because it captures something important. With Betweeness, we're looking at ALL the shortest paths between EVERY pair of nodes in the graph. [Wikipedia](https://en.wikipedia.org/wiki/Centrality) is quite handy on this and says: \"Betweenness centrality quantifies the number of times a node acts as a bridge along the shortest path between two other nodes.\"\n",
    "\n",
    "Do you see why we might be interested in Betweeness Centrality in the context of the Roman communications networks? \n",
    "\n",
    "We can call networkx to calculate betwenness_centrality on our graph like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5ec2b-a346-4636-a1da-802eddcf9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab42e14-bdfa-49e2-980a-800aaf7c473a",
   "metadata": {},
   "source": [
    "But that's rather hard to make sense of, eh? So let's make a nice dataframe with that metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce2f59-bee5-4c3e-b200-faf7bb6631c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get betweenness scores for the graph, and call that variable 'bw'\n",
    "bw = nx.betweenness_centrality(G)\n",
    "\n",
    "# get the labels from the node attributes in our graph\n",
    "labels = nx.get_node_attributes(G, 'label')\n",
    "\n",
    "# make a dataframe where we have three columns node, betweenness, and label and make sure we grab the relevant node data each time!\n",
    "bw_df = pd.DataFrame([\n",
    "    {'node': node, 'betweenness': bw[node], 'label': labels.get(node, node)}\n",
    "    for node in G.nodes()\n",
    "])\n",
    "\n",
    "# it's always nice to sort your data; here we'll sort it by the middle column 'betweeness'\n",
    "bw_df = bw_df.sort_values(by='betweenness', ascending=False)\n",
    "\n",
    "# and let's take a look:\n",
    "bw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a6766-d074-44fc-be9c-7e6240db0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we can make a nice bar chart from the df:\n",
    "num_nodes_to_inspect = 10\n",
    "bw_df[:num_nodes_to_inspect].plot(x='label', y='betweenness', color='green', kind='barh').invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe4265-9cde-42e9-b8c2-24e0dc47022d",
   "metadata": {},
   "source": [
    "#### Your observations\n",
    "Interesting! You might have to look some of those places up. Do you spot any names that appeared when we looked at degree centrality? When you start looking at the graph and you start spotting particular nodes (or relationships) that keep emerging, maybe you're starting to spot something worth investigating further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed280b-d3f8-4446-8ee4-9c9b026d9ce1",
   "metadata": {},
   "source": [
    "### Modularity & Communities\n",
    "\n",
    "The last metric we'll look at today is called 'modularity'. You'll also see this called 'community detection'. There are a variety of algorithms for doing this, but all of them are trying to answer the question, 'are there natural subgraphs in this data'? That is to say: can we detect groups of nodes who are more alike to each other than they are not? If we had a network of friend relationships at a school, modularity might help us detect the jocks from the nerds, the band kid from the theatre kids. Some of these methods take into account the attributes of the edges - strength of the relationship, number of days to travel, number of interactions between the two nodes, whatever - rather than just the presence/absence of a relationship, so you always - always! - have to think hard what a given metric means in a given context. Also: there is an element of probability in these algorithms. They do have a chance of returning results that are wrong.\n",
    "\n",
    "With our data on Roman connectivity, what do you think 'community.greedy_modularity_communities' might imply? (Hint: you'll have to search for networkx and that algorithmn, and track back through the documentation to work it out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de4092-6890-438d-a0d4-034f7bd7cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get communities and labels from the graph\n",
    "# other algorithms:\n",
    "# nx.community.louvain_communities(G) - Louvain method\n",
    "# nx.community.label_propagation_communities(G) - Label propagation\n",
    "# nx.community.asyn_lpa_communities(G) - Asynchronous label propagation\n",
    "\n",
    "\n",
    "# let's run the metric, and grab the labels\n",
    "communities = nx.community.greedy_modularity_communities(G)\n",
    "labels = nx.get_node_attributes(G, 'label')\n",
    "\n",
    "# Create a mapping from node to community so that the result for each node is correctly put together\n",
    "node_to_community = {}\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        node_to_community[node] = i\n",
    "\n",
    "# then we'll make our dataframe\n",
    "community_df = pd.DataFrame([\n",
    "    {'node': node, 'community': node_to_community[node], 'label': labels.get(node, node)}\n",
    "    for node in G.nodes()\n",
    "])\n",
    "\n",
    "# we'll sort it\n",
    "community_df = community_df.sort_values(by='community')\n",
    "\n",
    "# now let's have a look!\n",
    "community_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d816d9-1115-4028-ac58-2e4d419496cf",
   "metadata": {},
   "source": [
    "So like I was saying, there is also a chance that a city/settlement/node is assigned to the wrong community. With modularity, you can measure roughly how well the algorithm has found actual communities and grouped the nodes correctly. The closer to 1, the greater the chance that what you've found is actually there in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177d607-5083-448f-9ff5-e3ab85755458",
   "metadata": {},
   "outputs": [],
   "source": [
    "modularity_score = nx.community.modularity(G, communities)\n",
    "print(f\"Modularity score: {modularity_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3625ce-ffb2-4adf-88ea-231dec524565",
   "metadata": {},
   "source": [
    "It'd be nice to know where a particular city is grouped. We can do this by filtering the data frame according to the label field for a particular place, eg 'Roma':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9cd1a1-5070-48d3-a4e4-0ce653d52209",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_df[community_df['label'] == 'Roma']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edf1af-6641-46e6-b1d0-97e009b48f1c",
   "metadata": {},
   "source": [
    "Ok, great: we know the community number for Rome. We're going to plot the Roman network data again, but this time we're going to colour it by communities we've found. So first we figure out how many unique colours we'll need (one per community) and then we'll assign a colour palette to those communities. Then we also assign those colours to the individual node. Then we'll plot the graph like we did before, but telling it to use those colours. Also, let's create a legend too while we're at it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d45078-ee1f-4ba7-9884-102424fc30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Get community colors - create a color map\n",
    "communities_list = community_df['community'].unique()\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(communities_list)))\n",
    "community_colors = dict(zip(communities_list, colors))\n",
    "\n",
    "# Create node color list based on community\n",
    "node_colors = [community_colors[node_to_community[node]] for node in G.nodes()]\n",
    "\n",
    "# Choose layout\n",
    "pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "\n",
    "# Draw the network\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5, edge_color='gray')\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, \n",
    "                       node_size=500, alpha=0.8)\n",
    "\n",
    "# Draw labels\n",
    "labels = nx.get_node_attributes(G, 'label')\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=10)\n",
    "\n",
    "# Create legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=community_colors[comm], \n",
    "                             markersize=10, label=f'Community {comm}')\n",
    "                  for comm in sorted(communities_list)]\n",
    "plt.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "\n",
    "plt.title(\"Network Graph - Colored by Community\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print community info\n",
    "print(f\"Rome is in community {node_to_community[community_df[community_df['label'] == 'Roma']['node'].iloc[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dff4ea-1ddf-4ec0-8514-3eda30b58353",
   "metadata": {},
   "source": [
    "Since we now know which community Rome is in _at least today, when I ran this code_ we can plot _just_ the nodes in its community, `3`. When you ran the notebook today, Rome might've been assigned a different community label. So you'll need to change the code below appropriately!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f3910-49e2-42b3-b258-e7b65c36407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nodes in community 3\n",
    "community_3_nodes = community_df[community_df['community'] == 3]['node'].tolist()\n",
    "\n",
    "# Create subgraph with only community 3 nodes\n",
    "G_community_3 = G.subgraph(community_3_nodes)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Choose layout\n",
    "#pos = nx.spring_layout(G_community_3, k=1, iterations=500)\n",
    "pos = nx.fruchterman_reingold_layout(G_community_3, k=1, iterations=500)\n",
    "\n",
    "# Draw the network\n",
    "nx.draw_networkx_edges(G_community_3, pos, alpha=0.5, edge_color='gray')\n",
    "nx.draw_networkx_nodes(G_community_3, pos, node_color='lightcoral', \n",
    "                       node_size=500, alpha=0.8)\n",
    "\n",
    "# Draw labels\n",
    "labels = nx.get_node_attributes(G_community_3, 'label')\n",
    "nx.draw_networkx_labels(G_community_3, pos, labels, font_size=12)\n",
    "\n",
    "plt.title(\"Community 3 - Rome's Community\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some info about this community\n",
    "print(f\"Community 3 has {len(community_3_nodes)} nodes:\")\n",
    "print(community_df[community_df['community'] == 3]['label'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858ae14-da71-40a2-8609-66da4d174148",
   "metadata": {},
   "source": [
    "#### Your Observations\n",
    "\n",
    "So... what stands out for you? Make some observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a9193-221a-4496-9010-d794a82232e0",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Take a look at [[network-exercise]] and see how you get on.\n",
    "\n",
    "For reference, I also show you how to do all of this in R in the [[networks-via-R.ipynb]] notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f326ad-0a20-4b75-97c6-25868d0ef5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7ea2b59-4732-457c-a78c-fa89eeafaa77",
   "metadata": {},
   "source": [
    "Moving onto our [[next notebook|abm.ipynb]] we'll create some software agents and let them swarm all over this network. This is a kind of artificial intelligence where we look for emergent properties of behaviour. This [older piece by me](https://core.ac.uk/download/pdf/147823016.pdf) shows you some of what you might encounter..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
